{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: 2000.csv\n",
      "Reading: 2001.csv\n",
      "Reading: 2002.csv\n",
      "Reading: 2003.csv\n",
      "Reading: 2004.csv\n",
      "Reading: 2005.csv\n",
      "Reading: 2006.csv\n",
      "Reading: 2007.csv\n",
      "Reading: 2008.csv\n",
      "Reading: 2009.csv\n",
      "Reading: 2010.csv\n",
      "Reading: 2011.csv\n",
      "Reading: 2012.csv\n",
      "Reading: 2013.csv\n",
      "Reading: 2014.csv\n",
      "Reading: 2015.csv\n",
      "Reading: 2016.csv\n",
      "Reading: 2017.csv\n",
      "Reading: 2018.csv\n",
      "Reading: 2019.csv\n",
      "Reading: 2020.csv\n",
      "Reading: 2021.csv\n",
      "DONE. Shape: (5932265, 60)\n"
     ]
    }
   ],
   "source": [
    "#Step1: combine anualized patent data from 2000 to 2021\n",
    "folder_path = \"/Users/liusiyi/Library/CloudStorage/OneDrive-IndianaUniversity/Research/patent/patent data/annualized data/csv data\"   #fill the file path here\n",
    "csv_files = sorted(glob.glob(os.path.join(folder_path, \"*.csv\")))\n",
    "df_list = []\n",
    "for f in csv_files:\n",
    "    print(\"Reading:\", os.path.basename(f))\n",
    "    df = pd.read_csv(f, dtype=str)  \n",
    "    df_list.append(df)\n",
    "\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "combined_df.to_csv(\"/Users/liusiyi/Desktop/patents_2000_2021_combined_copy.csv\", index=False)\n",
    "print(\"DONE. Shape:\", combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved minimal dataset: (5932265, 3)\n"
     ]
    }
   ],
   "source": [
    "keep_cols = [\"cpc_sections\", \"grant_year\", \"patent_number\"] #keep the useful column\n",
    "combined_df = combined_df[keep_cols]\n",
    "combined_df.to_csv(\"/Users/liusiyi/Desktop/patents_2000_2021_minimal.csv\", index=False)\n",
    "print(\"✅ Saved minimal dataset:\", combined_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved to Desktop! Shape: (5730702, 3)\n"
     ]
    }
   ],
   "source": [
    "combined_df = combined_df.rename(columns={'patent_number': 'patent_id'}) #rename patent id for further matching\n",
    "combined_unique = combined_df.drop_duplicates(subset=['patent_id'], keep='first') #drop duplications and rename the dataset combined_unique\n",
    "combined_unique.to_csv(\n",
    "    \"/Users/liusiyi/Desktop/patents_2000_2021_unique_copy.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"✅ Saved to Desktop! Shape:\", combined_unique.shape) #save new file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of missing abstract: 522167\n",
      "Total lines: 5730702\n",
      "missing ratio: 9.11%\n"
     ]
    }
   ],
   "source": [
    "#Step 2: Merge annualized data with patents' abstract\n",
    "tsv_path = \"/Users/liusiyi/Library/CloudStorage/OneDrive-IndianaUniversity/Research/patent/patent data/add_vaiable/granted data/g_patent_abstract.tsv\"   # enter file path for patent abstract \n",
    "df_abs = pd.read_csv(tsv_path, sep=\"\\t\", dtype=str, low_memory=False)\n",
    "merged_df = combined_unique.merge(\n",
    "    df_abs,\n",
    "    on='patent_id',\n",
    "    how='left'  \n",
    ")\n",
    "merged_df = merged_df[['patent_id', 'cpc_sections', 'grant_year', 'patent_abstract']] #change column order\n",
    "output_path = \"/Users/liusiyi/Documents/patents_2000_2021_with_abstract_copy.csv\"\n",
    "merged_df.to_csv(output_path, index=False)\n",
    "\n",
    "nan_count = merged_df['patent_abstract'].isna().sum() #calculate the number of missing abstract (which is 52,2167)\n",
    "total = len(merged_df) #calculate the number of  abstract (which is 5,730,702)\n",
    "nan_ratio = nan_count / total #calculate ratio (which is 9.1%)\n",
    "\n",
    "print(\"number of missing abstract:\", nan_count)\n",
    "print(\"Total lines:\", total)\n",
    "print(\"missing ratio: {:.2%}\".format(nan_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3516106 entries, 0 to 3516105\n",
      "Data columns (total 20 columns):\n",
      " #   Column                            Dtype \n",
      "---  ------                            ----- \n",
      " 0   patent_id                         object\n",
      " 1   founding_year                     object\n",
      " 2   founding_score                    object\n",
      " 3   VC_backed_assignee                object\n",
      " 4   VC_score                          object\n",
      " 5   initassignee_id                   object\n",
      " 6   initassignee_organization         object\n",
      " 7   same_as20220630pv                 object\n",
      " 8   assignee_organization_20220630pv  object\n",
      " 9   assignee_id_20220630pv            object\n",
      " 10  initassignee_idxwalk20220630pv    object\n",
      " 11  Found in OC                       object\n",
      " 12  company_number                    object\n",
      " 13  gvkey                             object\n",
      " 14  CUSIP                             object\n",
      " 15  first_year_publicly_listed        object\n",
      " 16  UO_DISCERN                        object\n",
      " 17  SUB_DISCERN                       object\n",
      " 18  univ_hospital_gov                 object\n",
      " 19  is_US_assignee                    object\n",
      "dtypes: object(20)\n",
      "memory usage: 536.5+ MB\n"
     ]
    }
   ],
   "source": [
    "path2 = \"/Users/liusiyi/Library/CloudStorage/OneDrive-IndianaUniversity/Research/patent/1111/12706672/ocpb_assigneeatfiling.csv\"  #data from zenodo\n",
    "df2 = pd.read_csv(path2, dtype=str)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path2 = \"/Users/liusiyi/Library/CloudStorage/OneDrive-IndianaUniversity/Research/patent/1111/12706672/ocpb_assigneeatfiling.csv\"  #data from zenodo\n",
    "df2 = pd.read_csv(path2, dtype=str)\n",
    "merged2 = df2.merge(\n",
    "    merged_df,\n",
    "    on=\"patent_id\",\n",
    "    how=\"left\"\n",
    ") #merge pantent abstact with zenodo data using patent_id as a key\n",
    "merged2['grant_year'] = pd.to_numeric(merged2['grant_year'], errors='coerce') ## trasnform grant_year to number, or NAN\n",
    "merged2 = merged2[merged2['grant_year'].between(2000, 2021)] #merge with VC data\n",
    "merged2.to_csv(\"/Users/liusiyi/Desktop/vcpatent_2000_2021_copy.csv\", index=False) #save final dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2544381 entries, 0 to 2544380\n",
      "Data columns (total 23 columns):\n",
      " #   Column                            Dtype  \n",
      "---  ------                            -----  \n",
      " 0   patent_id                         object \n",
      " 1   founding_year                     float64\n",
      " 2   founding_score                    float64\n",
      " 3   VC_backed_assignee                float64\n",
      " 4   VC_score                          float64\n",
      " 5   initassignee_id                   object \n",
      " 6   initassignee_organization         object \n",
      " 7   same_as20220630pv                 int64  \n",
      " 8   assignee_organization_20220630pv  object \n",
      " 9   assignee_id_20220630pv            object \n",
      " 10  initassignee_idxwalk20220630pv    object \n",
      " 11  Found in OC                       float64\n",
      " 12  company_number                    object \n",
      " 13  gvkey                             float64\n",
      " 14  CUSIP                             object \n",
      " 15  first_year_publicly_listed        float64\n",
      " 16  UO_DISCERN                        float64\n",
      " 17  SUB_DISCERN                       float64\n",
      " 18  univ_hospital_gov                 float64\n",
      " 19  is_US_assignee                    float64\n",
      " 20  cpc_sections                      object \n",
      " 21  grant_year                        float64\n",
      " 22  patent_abstract                   object \n",
      "dtypes: float64(12), int64(1), object(10)\n",
      "memory usage: 446.5+ MB\n"
     ]
    }
   ],
   "source": [
    "#Step 3: data cleaning \n",
    "df = pd.read_csv(\"/Users/liusiyi/Desktop/vcpatent_2000_2021_copy.csv\") #enter the path for patent data saved in appenddata_code.ipynb\n",
    "df.info() #check the variable information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314889, 23)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfnew = df[(df['grant_year'] >= 2000) & (df['grant_year'] <= 2021)] #keep patent between 2000 and 2021\n",
    "dfnew = df[df['cpc_sections'].str.contains('C', na=False)] #keep patent which contains section C\n",
    "dfnew.shape #check the shape (31,4889,23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop the observations with empty abstracts \n",
    "before = len(dfnew)\n",
    "\n",
    "df_clean = dfnew.dropna(subset=[\"patent_abstract\"])\n",
    "df_clean = df_clean[df_clean[\"patent_abstract\"].str.strip() != \"\"]  # move NA value of abstarct\n",
    "\n",
    "after = len(df_clean)\n",
    "\n",
    "removed = before - after\n",
    "\n",
    "print(f\"Number of original sample: {before}\")\n",
    "print(f\"Number of sample after deleting: {after}\")\n",
    "print(f\"Number of deleted: {removed}\")\n",
    "\n",
    "output_path = \"/Users/liusiyi/Library/CloudStorage/OneDrive-IndianaUniversity/Research/1202/vc0021_C.csv\" #preserved clean version\n",
    "df_clean.to_csv(output_path, index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
